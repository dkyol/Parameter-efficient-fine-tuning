{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b5b048",
   "metadata": {},
   "source": [
    "![NVIDIA Logo](images/nvidia.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3051bd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e3afbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from llm_utils.nemo_service_models import NemoServiceBaseModel\n",
    "from llm_utils.models import PubmedModels\n",
    "from llm_utils.helpers import plot_experiment_results, accuracy_score\n",
    "from llm_utils.pubmedqa import generate_prompt_and_answer, strip_response\n",
    "from llm_utils.prompt_creators import create_prompt_with_examples, create_nemo_prompt_with_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ae09e6",
   "metadata": {},
   "source": [
    "## List Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fffddce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt8b: gpt-8b-000\n",
      "gpt20b: gpt20b\n",
      "gpt43b: gpt-43b-001\n"
     ]
    }
   ],
   "source": [
    "PubmedModels.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f50f353",
   "metadata": {},
   "source": [
    "## Generate Few-shot Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ade7334",
   "metadata": {},
   "source": [
    "**We will start with GPT43B which was instruction fine-tuned. To properly format example shots for this model we've provided the helper function `create_nemo_prompt_with_examples`.**\n",
    "\n",
    "**You'll notice a 3-shot prompt created by this helper function includes the addition of `User:` and `Assistant:` in various places to match GPT43B's instruction fine-tuning prompt template.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00d1b60",
   "metadata": {},
   "source": [
    "### Non-Instruction Fine-tuned Prompt Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe736a7",
   "metadata": {},
   "source": [
    "**GPT20B and GPT8B are not instruction fine-tuned models, and thus we only need to provide our example prompt/response shots in a straightforward manner. We've provided the `create_prompt_with_examples` helper function to accomplish this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149fc384",
   "metadata": {},
   "source": [
    "## Try Few-shot Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f19be945",
   "metadata": {},
   "outputs": [],
   "source": [
    "llms = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97ceab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llms['gpt8b'] = NemoServiceBaseModel(PubmedModels.gpt8b.value, create_prompt_with_examples=create_prompt_with_examples)\n",
    "llms['gpt20b'] = NemoServiceBaseModel(PubmedModels.gpt20b.value, create_prompt_with_examples=create_prompt_with_examples)\n",
    "llms['gpt43b'] = NemoServiceBaseModel(PubmedModels.gpt43b.value, create_prompt_with_examples=create_nemo_prompt_with_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02723e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt8b': <llm_utils.nemo_service_models.NemoServiceBaseModel at 0x7fbf3c6f3380>,\n",
       " 'gpt20b': <llm_utils.nemo_service_models.NemoServiceBaseModel at 0x7fbf3c6f3410>,\n",
       " 'gpt43b': <llm_utils.nemo_service_models.NemoServiceBaseModel at 0x7fbf3c6f3440>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1304ef43",
   "metadata": {},
   "source": [
    "### Few Shot Results with 43B Fine-Tuned Format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a0c3589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/dli/2-PubMedQA\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df60c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/workspace/dli/2-PubMedQA/data_62124.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0d662f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>good address</th>\n",
       "      <th>compare address</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14361 cupcake terrace</td>\n",
       "      <td>14361 cupofcake terrace</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13823 principle terrace</td>\n",
       "      <td>2689 principal highway</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>908 toolbox street</td>\n",
       "      <td>1209 main highway</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6785 wheel avenue</td>\n",
       "      <td>1809 main way</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3944 electric screwdriver road</td>\n",
       "      <td>3944 elecc screwdriver</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                    good address          compare address  label\n",
       "0           0           14361 cupcake terrace  14361 cupofcake terrace      1\n",
       "1           1         13823 principle terrace   2689 principal highway      0\n",
       "2           2              908 toolbox street        1209 main highway      0\n",
       "3           3               6785 wheel avenue            1809 main way      0\n",
       "4           4  3944 electric screwdriver road   3944 elecc screwdriver      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afed13e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Address: 13345 door parkway\n",
      "Compare Address: 13345 dor parkway\n",
      "Response from model: yes\n",
      "Actual answer: yes\n",
      "Response from model correct: True\n",
      "\n",
      "Good Address: 6494 bug parkway\n",
      "Compare Address: 6494 bg parkway\n",
      "Response from model: yes\n",
      "Actual answer: yes\n",
      "Response from model correct: True\n",
      "\n",
      "Good Address: 1635 arm road\n",
      "Compare Address: 7683 main place\n",
      "Response from model: no\n",
      "Actual answer: no\n",
      "Response from model correct: True\n",
      "\n",
      "Good Address: 9329 anchor place\n",
      "Compare Address: 9329 aynchzor place\n",
      "Response from model: yes\n",
      "Actual answer: yes\n",
      "Response from model correct: True\n",
      "\n",
      "Good Address: 9910 flower place\n",
      "Compare Address: 9910 flwe place\n",
      "Response from model: yes\n",
      "Actual answer: yes\n",
      "Response from model correct: True\n",
      "\n",
      "Good Address: 10393 chalk boulevard\n",
      "Compare Address: 10393 cfhtalk boulevard\n",
      "Response from model: no\n",
      "Actual answer: yes\n",
      "Response from model correct: False\n",
      "\n",
      "Good Address: 1519 boat center\n",
      "Compare Address: 10261 main lane\n",
      "Response from model: no\n",
      "Actual answer: no\n",
      "Response from model correct: True\n",
      "\n",
      "Good Address: 14682 rock road\n",
      "Compare Address: 12156 main center\n",
      "Response from model: no\n",
      "Actual answer: no\n",
      "Response from model correct: True\n",
      "\n",
      "Good Address: 13454 arrow center\n",
      "Compare Address: 13454 aro center\n",
      "Response from model: yes\n",
      "Actual answer: yes\n",
      "Response from model correct: True\n",
      "\n",
      "Good Address: 9825 belief place\n",
      "Compare Address: 13172 belief place\n",
      "Response from model: no\n",
      "Actual answer: no\n",
      "Response from model correct: True\n",
      "\n",
      "the accuracy is 0.9\n"
     ]
    }
   ],
   "source": [
    "rowNum = 20 \n",
    "c = 0\n",
    "for i in range(10, rowNum):\n",
    "    ##prompt = f'Should the following two addresses be linked {df['good address'][i]} and {df['compare address'][i]}?'\n",
    "    #prompt = f'Are the following addresses mispelled versions of the same address or two distinct addresses: {df['good address'][i]} and {df['compare address'][i]}? ANSWER (yes|no)'\n",
    "\n",
    "    fewPrompt = f'''Objective: Some addresses look the same, but indicate different physical locations and therefore they should not be linked, \n",
    "    one indicaation that two addresses should not be linked is they have different house numbers. Alternatively, some \n",
    "    addresses are not exact matches but should be linked, they often dont match because of a mispelling in one of the \n",
    "    street names.  For example, These pair of addresses should be matched: 990 sizzling place and 990 sizlig place. while, \n",
    "    this pair of streets 67 metal way and 87 petal drive indicate different address that should not be matched. \n",
    "    \n",
    "    QUESTION: Should the following two addresses be linked 14361 cupcake terrace and 14361 cupofcake terrace? \n",
    "    ANSWER (yes|no): \n",
    "    \n",
    "    Assistant:yes \n",
    "    \n",
    "    QUESTION: Should the following two addresses be linked 13823 principle terrace and 2689 principal highway? \n",
    "    ANSWER (yes|no): \n",
    "    \n",
    "    Assistant:no \n",
    "    \n",
    "    QUESTION: Should the following two addresses be linked 908 toolbox street and 1209 main highway? \n",
    "    ANSWER (yes|no): \n",
    "    \n",
    "    Assistant:no \n",
    "\n",
    "    QUESTION: Should the following two addresses be linked {df['good address'][i]} and {df['compare address'][i]}? \n",
    "    ANSWER (yes|no):'''\n",
    "    \n",
    "    response = llms['gpt43b'].generate(fewPrompt, tokens_to_generate=1, return_type='text').strip()\n",
    "\n",
    "    if df['label'][i] == 1:\n",
    "        label = 'yes'\n",
    "    else:\n",
    "        label = 'no'\n",
    "\n",
    "    print(f'Good Address: {df['good address'][i]}')\n",
    "    print(f'Compare Address: {df['compare address'][i]}')\n",
    "    \n",
    "    print(f'Response from model: {response}')\n",
    "    print(f'Actual answer: {label}')\n",
    "    correct = label == response\n",
    "    print(f'Response from model correct: {correct}\\n')\n",
    "    if correct:\n",
    "        c += 1\n",
    "\n",
    "print(f'the accuracy is {c/10}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
